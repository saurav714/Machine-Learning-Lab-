{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuy8cNEdsAhkn2FSobKuBH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurav714/Machine-Learning-Lab-/blob/main/Sentinal_distribution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lqawjRZMJdo",
        "outputId": "f925711d-66ba-4019-f37a-bae6a96a3d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.11/dist-packages (4.14.0)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "pip install tweepy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "\n",
        "# Twitter API credentials\n",
        "consumer_key = 'your_consumer_key'\n",
        "consumer_secret = 'your_consumer_secret'\n",
        "access_token = 'your_access_token'\n",
        "access_token_secret = 'your_access_token_secret'\n",
        "\n",
        "# Authenticate\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# Collect tweets\n",
        "tweets = api.search(q=\"your_keyword\", lang=\"en\", count=100)\n",
        "tweet_texts = [tweet.text for tweet in tweets]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "swDXGc_MOCco",
        "outputId": "543b4454-d9d0-4b2e-f2b4-16607f611339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'API' object has no attribute 'search'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-71c1f1d045ed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Collect tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"your_keyword\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtweet_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'API' object has no attribute 'search'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "\n",
        "# Twitter API credentials\n",
        "consumer_key = 'your_consumer_key'\n",
        "consumer_secret = 'your_consumer_secret'\n",
        "access_token = 'your_access_token'\n",
        "access_token_secret = 'your_access_token_secret'\n",
        "\n",
        "# Authenticate\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# Correct method for searching tweets\n",
        "tweets = api.search_tweets(q=\"your_keyword\", lang=\"en\", count=100)\n",
        "tweet_texts = [tweet.text for tweet in tweets]\n",
        "\n",
        "# Print the collected tweets\n",
        "for tweet in tweet_texts:\n",
        "    print(tweet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "lJKKiECbOPIH",
        "outputId": "10a04c74-7ea0-44a0-eb87-df5815555b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Unauthorized",
          "evalue": "401 Unauthorized\n89 - Invalid or expired token.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnauthorized\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-38f38e427804>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Correct method for searching tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"your_keyword\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtweet_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpagination_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36msearch_tweets\u001b[0;34m(self, q, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0m_Twitter\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0msearch\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdeveloper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0moverview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \"\"\"\n\u001b[0;32m-> 1146\u001b[0;31m         return self.request(\n\u001b[0m\u001b[1;32m   1147\u001b[0m             'GET', 'search/tweets', endpoint_parameters=(\n\u001b[1;32m   1148\u001b[0m                 \u001b[0;34m'q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geocode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lang'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'locale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mBadRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m401\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnauthorized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m403\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mForbidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnauthorized\u001b[0m: 401 Unauthorized\n89 - Invalid or expired token."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset (example with a CSV file)\n",
        "dataset = pd.read_csv('training.1600000.processed.noemoticon.csv')\n",
        "\n",
        "# Display the first few rows\n",
        "print(dataset.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "dx7a8I7BRlJo",
        "outputId": "3440502e-678d-4a9c-bd19-309ac45cd907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'training.1600000.processed.noemoticon.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-63d517796d63>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the dataset (example with a CSV file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training.1600000.processed.noemoticon.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Display the first few rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training.1600000.processed.noemoticon.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92SNCx2TSWGn",
        "outputId": "b71e37be-f3a1-41cb-b13f-946906a4663c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv', encoding='latin1')\n",
        "df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
        "print(df.iloc[0]['target'])\n",
        "print(df.iloc[0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "r-nkGzQFSzzP",
        "outputId": "2be114ef-74d4-419c-893f-aec97b8d4f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e666d1eed708>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ids'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'flag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # This will prompt you to upload files from your local system\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "w6pdKJL2anCv",
        "outputId": "78eddeec-3ab5-4606-daf4-91ce0929c36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ffdeb07e-a8c4-4c64-8297-c34e1feff377\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ffdeb07e-a8c4-4c64-8297-c34e1feff377\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-41375d8b00a4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This will prompt you to upload files from your local system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     result = _output.eval_js(\n\u001b[0m\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[1;32m    174\u001b[0m             \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2GRJ1LSdbgm",
        "outputId": "d22fc050-c8b3-4c11-cfe9-5f70cfa1ec37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Adjust the path to your specific folder and file name\n",
        "df = pd.read_csv('/content/drive/My Drive/datasets/training.1600000.processed.noemoticon.csv', encoding='latin1')\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "9PIxBFRSdzD3",
        "outputId": "f42d6a46-c6de-4b69-a25e-b1fde6a1d95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/datasets/training.1600000.processed.noemoticon.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-212d633b8215>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Adjust the path to your specific folder and file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/datasets/training.1600000.processed.noemoticon.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Display the first few rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/datasets/training.1600000.processed.noemoticon.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy the file from Google Drive to your current working directory\n",
        "file_id = '16qDhz3hhcKu3CQifZnupbiRniWyz6tou'\n",
        "destination = '/content/drive/My Drive/your_file_name'  # Change this to your desired file name or path\n",
        "\n",
        "# Use gdown to download the file\n",
        "import gdown\n",
        "\n",
        "# This will download the file from Google Drive to your current working directory\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', destination, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "jSLyQdoOd2Fe",
        "outputId": "8e647dbe-5b74-4b09-d78d-899724f7f9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=16qDhz3hhcKu3CQifZnupbiRniWyz6tou\n",
            "From (redirected): https://drive.google.com/uc?id=16qDhz3hhcKu3CQifZnupbiRniWyz6tou&confirm=t&uuid=12be97b8-90c2-41f2-981e-b105450f22bc\n",
            "To: /content/drive/My Drive/your_file_name\n",
            "100%|██████████| 239M/239M [00:03<00:00, 71.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/your_file_name'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the file into a dataframe (assuming it's a CSV)\n",
        "df = pd.read_csv(destination, encoding='latin1')\n",
        "df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_BjdkbueN3V",
        "outputId": "120c2665-4097-4647-e01d-d747c3780a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   target         ids                          date      flag           user  \\\n",
            "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
            "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
            "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
            "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
            "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
            "\n",
            "                                                text  \n",
            "0  is upset that he can't update his Facebook by ...  \n",
            "1  @Kenichan I dived many times for the ball. Man...  \n",
            "2    my whole body feels itchy and like its on fire   \n",
            "3  @nationwideclass no, it's not behaving at all....  \n",
            "4                      @Kwesidei not the whole crew   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Data Preprocessing: Keep relevant columns and map sentiments\n",
        "df = df[['target', 'text']]  # Only keep the 'target' and 'text' columns\n",
        "df['target'] = df['target'].map({0: 'negative', 2: 'neutral', 4: 'positive'})  # Map target labels to text\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data into numerical form using CountVectorizer\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict the sentiment on the test set\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36vyL_8AeVLW",
        "outputId": "92fcac57-f86f-48ad-8b70-23df93cafb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-6365420b6429>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df['target'].map({0: 'negative', 2: 'neutral', 4: 'positive'})  # Map target labels to text\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.779825\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.79      0.76      0.78    159494\n",
            "    positive       0.77      0.80      0.78    160506\n",
            "\n",
            "    accuracy                           0.78    320000\n",
            "   macro avg       0.78      0.78      0.78    320000\n",
            "weighted avg       0.78      0.78      0.78    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gdown\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "import numpy as np\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Download file from Google Drive using the provided link\n",
        "file_id = '16qDhz3hhcKu3CQifZnupbiRniWyz6tou'\n",
        "destination = '/content/drive/My Drive/sentiment_data.csv'  # Modify this as needed\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', destination, quiet=False)\n",
        "\n",
        "df = df[['target', 'text']]  # Adjust these to your dataset's column names\n",
        "df['target'] = df['target'].map({0: 'negative', 2: 'neutral', 4: 'positive'})  # Map target labels\n",
        "\n",
        "\n",
        "# Split the data into training and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data into numerical format using CountVectorizer\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict the sentiment on the test set\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Visualization 1: Sentiment Distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='target', data=df, palette='Set2')\n",
        "plt.title('Sentiment Distribution (Positive, Neutral, Negative)')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "# Visualization 2: Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=['negative', 'neutral', 'positive'])\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['negative', 'neutral', 'positive'], yticklabels=['negative', 'neutral', 'positive'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Visualization 3: ROC Curve (for each class)\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "y_train_bin = lb.fit_transform(y_train)\n",
        "y_test_bin = lb.transform(y_test)\n",
        "\n",
        "# Get predicted probabilities\n",
        "y_pred_prob = model.predict_proba(X_test_vec)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(3):  # 3 classes (positive, neutral, negative)\n",
        "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_prob[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'Class {lb.classes_[i]} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line (no skill)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "64miB5dafhwe",
        "outputId": "d6ef8981-5257-4ee8-8d9f-7df37d2a7ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=16qDhz3hhcKu3CQifZnupbiRniWyz6tou\n",
            "From (redirected): https://drive.google.com/uc?id=16qDhz3hhcKu3CQifZnupbiRniWyz6tou&confirm=t&uuid=5fae128f-c506-42d9-91ba-4475efda10a0\n",
            "To: /content/drive/My Drive/sentiment_data.csv\n",
            "100%|██████████| 239M/239M [00:01<00:00, 160MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['target', 'text'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-545d1e59eb2d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'https://drive.google.com/uc?id={file_id}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Adjust these to your dataset's column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'negative'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'neutral'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'positive'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Map target labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['target', 'text'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['target', 'text']]  # Adjust these to your dataset's column names\n",
        "df['target'] = df['target'].map({0: 'negative', 2: 'neutral', 4: 'positive'})  # Map target labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "6xmmvEI_gIqV",
        "outputId": "6f035e8f-037b-4110-fb63-ca2f0129117b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['target', 'text'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-80e2793ca6fd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Adjust these to your dataset's column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'negative'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'neutral'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'positive'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Map target labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['target', 'text'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset again\n",
        "df = pd.read_csv(destination, encoding='latin1')\n",
        "\n",
        "# Check the columns of the dataset\n",
        "print(df.columns)\n",
        "\n",
        "# Display the first few rows to better understand the structure\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XstlPuKfvi1",
        "outputId": "4938187a-220b-4cc4-d09a-cd9db909c665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['0', '1467810369', 'Mon Apr 06 22:19:45 PDT 2009', 'NO_QUERY',\n",
            "       '_TheSpecialOne_',\n",
            "       '@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D'],\n",
            "      dtype='object')\n",
            "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
            "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
            "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
            "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
            "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
            "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
            "\n",
            "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
            "0  is upset that he can't update his Facebook by ...                                                                   \n",
            "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
            "2    my whole body feels itchy and like its on fire                                                                    \n",
            "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
            "4                      @Kwesidei not the whole crew                                                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['target', 'text']]  # Adjust these to your dataset's column names\n",
        "df['target'] = df['target'].map({0: 'negative', 2: 'neutral', 4: 'positive'})  # Map target labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "Cd5mvMPJfz3d",
        "outputId": "e660e6dc-c408-4ee9-9d64-8a0b9c3541ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['target', 'text'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-80e2793ca6fd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Adjust these to your dataset's column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'negative'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'neutral'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'positive'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Map target labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['target', 'text'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset again\n",
        "df = pd.read_csv(destination, encoding='latin1')\n",
        "\n",
        "# Check the columns of the dataset\n",
        "print(df.columns)\n",
        "\n",
        "# Display the first few rows to better understand the structure\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQpWH2mggPL9",
        "outputId": "8af878e4-732c-44b2-abf5-64fb1a9fbd19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['0', '1467810369', 'Mon Apr 06 22:19:45 PDT 2009', 'NO_QUERY',\n",
            "       '_TheSpecialOne_',\n",
            "       '@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D'],\n",
            "      dtype='object')\n",
            "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
            "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
            "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
            "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
            "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
            "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
            "\n",
            "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
            "0  is upset that he can't update his Facebook by ...                                                                   \n",
            "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
            "2    my whole body feels itchy and like its on fire                                                                    \n",
            "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
            "4                      @Kwesidei not the whole crew                                                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['target', 'text']]  # Adjust these to your dataset's column names\n",
        "df['target'] = df['target'].map({0: 'negative', 2: 'neutral', 4: 'positive'})  # Map target labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "Y4CmYYnzgTh9",
        "outputId": "46f5c409-b2e3-49ce-e3df-3942ce380885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['target', 'text'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-80e2793ca6fd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Adjust these to your dataset's column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'negative'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'neutral'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'positive'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Map target labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['target', 'text'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset again\n",
        "df = pd.read_csv(destination, encoding='latin1')\n",
        "\n",
        "# Check the column names of the dataset\n",
        "print(df.columns)\n",
        "\n",
        "# Display the first few rows to better understand the structure\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OibegNBega3N",
        "outputId": "fcc4bc4c-866f-4902-81ed-6230bed96691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['0', '1467810369', 'Mon Apr 06 22:19:45 PDT 2009', 'NO_QUERY',\n",
            "       '_TheSpecialOne_',\n",
            "       '@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D'],\n",
            "      dtype='object')\n",
            "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
            "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
            "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
            "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
            "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
            "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
            "\n",
            "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
            "0  is upset that he can't update his Facebook by ...                                                                   \n",
            "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
            "2    my whole body feels itchy and like its on fire                                                                    \n",
            "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
            "4                      @Kwesidei not the whole crew                                                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download necessary NLTK datasets\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')  # VADER lexicon for sentiment analysis\n",
        "\n",
        "# Load dataset with a different encoding\n",
        "file_path = '/content/drive/MyDrive/tw/training.1600000.processed.noemoticon.csv'  # Adjust the path as per your directory\n",
        "df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
        "\n",
        "# Rename columns for clarity\n",
        "df.columns = ['tweet_id', 'user_id', 'timestamp', 'query', 'user_handle', 'tweet_text']\n",
        "\n",
        "# Display the first few rows to verify the column renaming\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Sentiment Analysis using VADER\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Create sentiment labels: Positive if compound score > 0.05, Negative if compound score < -0.05, Neutral if between -0.05 and 0.05\n",
        "def get_sentiment(text):\n",
        "    score = sia.polarity_scores(text)['compound']\n",
        "    if score > 0.05:\n",
        "        return 'positive'\n",
        "    elif score < -0.05:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "df['sentiment'] = df['tweet_text'].apply(get_sentiment)\n",
        "\n",
        "# Sentiment distribution\n",
        "print(\"\\nSentiment distribution:\")\n",
        "print(df['sentiment'].value_counts())\n",
        "\n",
        "# Data Preprocessing: Tokenization, removing stopwords, and lemmatization using regex\n",
        "def clean_text(text):\n",
        "    # Use regular expressions to tokenize the text (alternative to word_tokenize)\n",
        "    tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "    # Remove stopwords and non-alphabetic tokens\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatize words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply cleaning to the tweet_text column\n",
        "df['cleaned_text'] = df['tweet_text'].apply(clean_text)\n",
        "\n",
        "# Display the cleaned tweets\n",
        "print(\"\\nCleaned Tweets (First 5):\")\n",
        "print(df['cleaned_text'].head())\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df['cleaned_text']\n",
        "y = df['sentiment']\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert text data into numerical representation using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predictions and evaluation\n",
        "+\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Display accuracy and classification report\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Visualize Sentiment Distribution\n",
        "sentiment_counts = df['sentiment'].value_counts()\n",
        "sentiment_counts.plot(kind='bar', color=['red', 'green', 'gray'], title='Sentiment Distribution')\n",
        "plt.xticks(ticks=[0, 1, 2], labels=['Negative', 'Neutral', 'Positive'], rotation=0)\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ah_MrRVdglXF",
        "outputId": "7177d99c-81e7-4083-afd4-ef30faf9202d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First few rows of the dataset:\n",
            "   tweet_id     user_id                     timestamp     query  \\\n",
            "0         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
            "1         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
            "2         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
            "3         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
            "4         0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
            "\n",
            "     user_handle                                         tweet_text  \n",
            "0  scotthamilton  is upset that he can't update his Facebook by ...  \n",
            "1       mattycus  @Kenichan I dived many times for the ball. Man...  \n",
            "2        ElleCTF    my whole body feels itchy and like its on fire   \n",
            "3         Karoli  @nationwideclass no, it's not behaving at all....  \n",
            "4       joy_wolf                      @Kwesidei not the whole crew   \n",
            "\n",
            "Missing values:\n",
            "tweet_id       0\n",
            "user_id        0\n",
            "timestamp      0\n",
            "query          0\n",
            "user_handle    0\n",
            "tweet_text     0\n",
            "dtype: int64\n",
            "\n",
            "Sentiment distribution:\n",
            "sentiment\n",
            "positive    741343\n",
            "neutral     443835\n",
            "negative    414821\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Cleaned Tweets (First 5):\n",
            "0    upset update facebook texting might cry result...\n",
            "1    kenichan dived many time ball managed save 50 ...\n",
            "2                      whole body feel itchy like fire\n",
            "3                     nationwideclass behaving mad see\n",
            "4                                  kwesidei whole crew\n",
            "Name: cleaned_text, dtype: object\n",
            "\n",
            "Accuracy: 0.7449979166666667\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.60      0.70    124234\n",
            "     neutral       0.81      0.57      0.67    132811\n",
            "    positive       0.70      0.93      0.80    222955\n",
            "\n",
            "    accuracy                           0.74    480000\n",
            "   macro avg       0.78      0.70      0.72    480000\n",
            "weighted avg       0.76      0.74      0.74    480000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAHHCAYAAACWQK1nAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASStJREFUeJzt3Xl0FGX+9v+rE+jORicsIQEJBNkDCLLFOCqikVbjPKKooKiAIMIElEXBzCgBZxwcFEUFQWeeL8GFB8SvMrIFMSwuRJYg+yI6IIyQBISkASEJyf37w1/q0CRIwIJO4P06p86h6/70XZ80RfqiuqraYYwxAgAAwO8S4O8GAAAALgeEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAJdUv379FBsb6+82/C4tLU0Oh0N79uy56Ns68zXfs2ePHA6HXnnllYu+bUkaN26cHA7HJdkW4E+EKuAytnnzZt13331q1KiRgoKCdNVVV+m2227Tm2++eVG3u3//fo0bN04bNmy4qNu5WH755ReNGzdOK1asqFD9ihUr5HA4rMXlcikqKko333yz/v73v+vgwYN+6etSqsy9AZeKg+/+Ay5Pq1atUrdu3dSwYUP17dtX0dHR2rdvn7755hv98MMP+v777y/attetW6fOnTtrxowZ6tevn89YUVGRSkpK5HK5Ltr2f69Dhw4pMjJSqampGjdu3DnrV6xYoW7duunJJ59U586dVVxcrIMHD2rVqlWaP3++wsPD9eGHH+qWW26xnlNcXKyioiK5XK4KH8U5375Knfma79mzR40bN9bLL7+sp59+usLzXGhvp06d0qlTpxQUFGTLtoDKqpq/GwBwcbz44osKDw/X2rVrFRER4TOWm5vrn6YkVa9e3W/bvthuvPFG3XfffT7rNm7cqO7du6tnz57atm2b6tWrJ0kKDAxUYGDgRe3n+PHjCg0N9ftrXq1aNVWrxtsNLn98/Adcpn744Qe1bt26TKCSpLp165ZZ9/7776tjx44KDg5WrVq11Lt3b+3bt8+n5uabb1abNm20bds2devWTSEhIbrqqqs0ceJEq2bFihXq3LmzJKl///7WR2JpaWmSfvv8nqlTp+rqq69WSEiIunfvrn379skYo7/+9a9q0KCBgoODdffdd+vw4cNl+l+8eLFuvPFGhYaGqkaNGkpKStLWrVt9avr166ewsDD99NNP6tGjh8LCwhQZGamnn35axcXFVj+RkZGSpPHjx1v9n8+RodO1a9dOkydPVl5enqZMmWKtL++cqnXr1snj8ahOnToKDg5W48aN9dhjj1Wor9Kf7YcfftCdd96pGjVqqE+fPuW+5qd77bXX1KhRIwUHB6tr167asmWLz/jNN9+sm2++uczzTp/zXL2Vd07VqVOn9Ne//lVNmjSRy+VSbGys/vznP6ugoMCnLjY2VnfddZe++uordenSRUFBQbr66qv17rvvlv+CA35EqAIuU40aNVJWVlaZN8nyvPjii3r00UfVrFkzvfrqqxo+fLgyMjJ00003KS8vz6f2yJEjuv3229WuXTtNmjRJLVu21JgxY7R48WJJUqtWrfTCCy9IkgYNGqT33ntP7733nm666abf7OGDDz7QW2+9pWHDhmnUqFFauXKlHnjgAT333HNKT0/XmDFjNGjQIM2fP7/MR1bvvfeekpKSFBYWpn/84x96/vnntW3bNt1www1lTgQvLi6Wx+NR7dq19corr6hr166aNGmS3nnnHUlSZGSkpk2bJkm65557rP7vvffec76OZ3PfffcpODhYn3322VlrcnNz1b17d+3Zs0fPPvus3nzzTfXp00fffPNNhfs6deqUPB6P6tatq1deeUU9e/b8zb7effddvfHGG0pOTlZKSoq2bNmiW265RTk5Oef1813IazZw4ECNHTtWHTp00GuvvaauXbtqwoQJ6t27d5na77//Xvfdd59uu+02TZo0STVr1lS/fv3KhGbA7wyAy9Jnn31mAgMDTWBgoElISDCjR482S5YsMYWFhT51e/bsMYGBgebFF1/0Wb9582ZTrVo1n/Vdu3Y1ksy7775rrSsoKDDR0dGmZ8+e1rq1a9caSWbGjBll+urbt69p1KiR9Xj37t1GkomMjDR5eXnW+pSUFCPJtGvXzhQVFVnrH3zwQeN0Os3JkyeNMcYcPXrUREREmMcff9xnO9nZ2SY8PNxnfd++fY0k88ILL/jUXnvttaZjx47W44MHDxpJJjU1tUz/5Vm+fLmRZObOnXvWmnbt2pmaNWtaj2fMmGEkmd27dxtjjPnkk0+MJLN27dqzzvFbfZX+bM8++2y5Y+W95sHBwea///2vtX716tVGkhkxYoS1rmvXrqZr167nnPO3ektNTTWnv91s2LDBSDIDBw70qXv66aeNJLNs2TJrXaNGjYwk88UXX1jrcnNzjcvlMqNGjSqzLcCfOFIFXKZuu+02ZWZm6v/8n/+jjRs3auLEifJ4PLrqqqv06aefWnUff/yxSkpK9MADD+jQoUPWEh0drWbNmmn58uU+84aFhenhhx+2HjudTnXp0kX/+c9/fle/999/v8LDw63H8fHxkqSHH37Y53yc+Ph4FRYW6qeffpIkLV26VHl5eXrwwQd9+g8MDFR8fHyZ/iVp8ODBPo9vvPHG393/uYSFheno0aNnHS/9mHbBggUqKiq64O0MGTKkwrU9evTQVVddZT3u0qWL4uPjtWjRogvefkWUzj9y5Eif9aNGjZIkLVy40Gd9XFycbrzxRutxZGSkWrRocdH/zoDzRagCLmOdO3fWxx9/rCNHjmjNmjVKSUnR0aNHdd9992nbtm2SpF27dskYo2bNmikyMtJn2b59e5mT2hs0aFDm/JiaNWvqyJEjv6vXhg0b+jwuDVgxMTHlri/d3q5duyRJt9xyS5n+P/vsszL9BwUFWef/2Nn/uRw7dkw1atQ463jXrl3Vs2dPjR8/XnXq1NHdd9+tGTNmlDnH6LdUq1ZNDRo0qHB9s2bNyqxr3rz5Rb931o8//qiAgAA1bdrUZ310dLQiIiL0448/+qw/c9+QLs3fGXC+uBwDuAI4nU517txZnTt3VvPmzdW/f3/NnTtXqampKikpkcPh0OLFi8u9Gi0sLMzn8dmuWDO/8+4sZ5v3XNsrKSmR9Ot5VdHR0WXqzrzq7GJfcVeeoqIifffdd2rTps1ZaxwOhz766CN98803mj9/vpYsWaLHHntMkyZN0jfffFPm76E8LpdLAQH2/l/Z4XCU+3dbemL/7527Ii7WPgfYjVAFXGE6deokSTpw4IAkqUmTJjLGqHHjxmrevLkt27iUd89u0qSJpF+vaExMTLRlTrv7/+ijj3TixAl5PJ5z1l533XW67rrr9OKLL2rWrFnq06ePZs+erYEDB9reV+lRvtN99913PlcK1qxZs9yP2c48mnQ+vTVq1EglJSXatWuXWrVqZa3PyclRXl6eGjVqVOG5gMqEj/+Ay9Ty5cvL/Z986fksLVq0kCTde++9CgwM1Pjx48vUG2P0888/n/e2Q0NDJanMlYMXg8fjkdvt1t///vdyz0W6kLuZh4SESLKn/40bN2r48OGqWbOmkpOTz1p35MiRMq9/+/btJcn6CNDOviRp3rx51rlpkrRmzRqtXr1ad9xxh7WuSZMm2rFjh8/ruHHjRn399dc+c51Pb3feeackafLkyT7rX331VUlSUlLSef0cQGXBkSrgMjVs2DD98ssvuueee9SyZUsVFhZq1apVmjNnjmJjY9W/f39Jv75p/u1vf1NKSor27NmjHj16qEaNGtq9e7c++eQTDRo06Lzvut2kSRNFRERo+vTpqlGjhkJDQxUfH6/GjRvb/nO63W5NmzZNjzzyiDp06KDevXsrMjJSe/fu1cKFC/WHP/zB5/5QFREcHKy4uDjNmTNHzZs3V61atdSmTZvf/PhOkr788kudPHlSxcXF+vnnn/X111/r008/VXh4uD755JNyP54sNXPmTL311lu655571KRJEx09elT//Oc/5Xa7rRByoX2dTdOmTXXDDTdoyJAhKigo0OTJk1W7dm2NHj3aqnnsscf06quvyuPxaMCAAcrNzdX06dPVunVreb3eC3rN2rVrp759++qdd95RXl6eunbtqjVr1mjmzJnq0aOHunXrdkE/D+B3/rrsEMDFtXjxYvPYY4+Zli1bmrCwMON0Ok3Tpk3NsGHDTE5OTpn6//3f/zU33HCDCQ0NNaGhoaZly5YmOTnZ7Ny506rp2rWrad26dZnnnnl5vTHG/Pvf/zZxcXGmWrVqPrdXONvl/S+//LLP8892m4LSWxGceeuB5cuXG4/HY8LDw01QUJBp0qSJ6devn1m3bp1Pn6GhoWX6P/OSf2OMWbVqlenYsaNxOp3nvL1Caa+lS/Xq1U1kZKS56aabzIsvvmhyc3PLPOfMWyqsX7/ePPjgg6Zhw4bG5XKZunXrmrvuusun/9/q62w/W+nY2V7zSZMmmZiYGONyucyNN95oNm7cWOb577//vrn66quN0+k07du3N0uWLCn37/xsvZX3+hYVFZnx48ebxo0bm+rVq5uYmBiTkpJi3SqjVKNGjUxSUlKZns52qwfAn/juPwAAABtwThUAAIANCFUAAAA2IFQBAADYgFAFAABgA0IVAACADQhVAAAANuDmn5dQSUmJ9u/frxo1alzSr/EAAAAXzhijo0ePqn79+r/5/ZqEqkto//79iomJ8XcbAADgAuzbt08NGjQ46zih6hKqUaOGpF//Utxut5+7AQAAFeH1ehUTE2O9j58NoeoSKv3Iz+12E6oAAKhiznXqDieqAwAA2IBQBQAAYANCFQAAgA0IVQAAADYgVAEAANiAUAUAAGADQhUAAIANCFUAAAA2IFQBAADYgFAFAABgA0IVAACADQhVAAAANiBUAQAA2IBQBQAAYANCFQAAgA2q+bsBVEIOh787uHwY4+8OAACXCEeqAAAAbECoAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsIFfQ1VsbKwcDkeZJTk5WZJ08uRJJScnq3bt2goLC1PPnj2Vk5PjM8fevXuVlJSkkJAQ1a1bV88884xOnTrlU7NixQp16NBBLpdLTZs2VVpaWplepk6dqtjYWAUFBSk+Pl5r1qzxGa9ILwAA4Mrl11C1du1aHThwwFqWLl0qSbr//vslSSNGjND8+fM1d+5crVy5Uvv379e9995rPb+4uFhJSUkqLCzUqlWrNHPmTKWlpWns2LFWze7du5WUlKRu3bppw4YNGj58uAYOHKglS5ZYNXPmzNHIkSOVmpqq9evXq127dvJ4PMrNzbVqztULAAC4wplK5KmnnjJNmjQxJSUlJi8vz1SvXt3MnTvXGt++fbuRZDIzM40xxixatMgEBASY7Oxsq2batGnG7XabgoICY4wxo0ePNq1bt/bZTq9evYzH47Eed+nSxSQnJ1uPi4uLTf369c2ECROMMaZCvVREfn6+kWTy8/Mr/By/kFjsWgAAVV5F378rzTlVhYWFev/99/XYY4/J4XAoKytLRUVFSkxMtGpatmyphg0bKjMzU5KUmZmptm3bKioqyqrxeDzyer3aunWrVXP6HKU1pXMUFhYqKyvLpyYgIECJiYlWTUV6KU9BQYG8Xq/PAgAALk+VJlTNmzdPeXl56tevnyQpOztbTqdTERERPnVRUVHKzs62ak4PVKXjpWO/VeP1enXixAkdOnRIxcXF5dacPse5einPhAkTFB4ebi0xMTHnfiEAAECVVGlC1f/9v/9Xd9xxh+rXr+/vVmyTkpKi/Px8a9m3b5+/WwIAABdJNX83IEk//vijPv/8c3388cfWuujoaBUWFiovL8/nCFFOTo6io6OtmjOv0iu9Iu/0mjOv0svJyZHb7VZwcLACAwMVGBhYbs3pc5yrl/K4XC65XK4KvgoAAKAqqxRHqmbMmKG6desqKSnJWtexY0dVr15dGRkZ1rqdO3dq7969SkhIkCQlJCRo8+bNPlfpLV26VG63W3FxcVbN6XOU1pTO4XQ61bFjR5+akpISZWRkWDUV6QUAAFzhLtGJ82dVXFxsGjZsaMaMGVNmbPDgwaZhw4Zm2bJlZt26dSYhIcEkJCRY46dOnTJt2rQx3bt3Nxs2bDDp6ekmMjLSpKSkWDX/+c9/TEhIiHnmmWfM9u3bzdSpU01gYKBJT0+3ambPnm1cLpdJS0sz27ZtM4MGDTIRERE+VxWeq5eK4Oq/K3ABAFR5FX3/9vtv/SVLlhhJZufOnWXGTpw4Yf70pz+ZmjVrmpCQEHPPPfeYAwcO+NTs2bPH3HHHHSY4ONjUqVPHjBo1yhQVFfnULF++3LRv3944nU5z9dVXmxkzZpTZ1ptvvmkaNmxonE6n6dKli/nmm2/Ou5dzIVRdgQsAoMqr6Pu3wxhj/Hqo7Ari9XoVHh6u/Px8ud1uf7dzdg6Hvzu4fPDPCwCqvIq+f1eKc6oAAACqOkIVAACADQhVAAAANiBUAQAA2IBQBQAAYANCFQAAgA0IVQAAADYgVAEAANiAUAUAAGADQhUAAIANCFUAAAA2IFQBAADYgFAFAABgA0IVAACADQhVAAAANiBUAQAA2IBQBQAAYANCFQAAgA0IVQAAADYgVAEAANiAUAUAAGADQhUAAIANCFUAAAA2IFQBAADYgFAFAABgA0IVAACADQhVAAAANiBUAQAA2IBQBQAAYANCFQAAgA0IVQAAADYgVAEAANiAUAUAAGADQhUAAIANCFUAAAA2IFQBAADYgFAFAABgA7+Hqp9++kkPP/ywateureDgYLVt21br1q2zxo0xGjt2rOrVq6fg4GAlJiZq165dPnMcPnxYffr0kdvtVkREhAYMGKBjx4751GzatEk33nijgoKCFBMTo4kTJ5bpZe7cuWrZsqWCgoLUtm1bLVq0yGe8Ir0AAIArk19D1ZEjR/SHP/xB1atX1+LFi7Vt2zZNmjRJNWvWtGomTpyoN954Q9OnT9fq1asVGhoqj8ejkydPWjV9+vTR1q1btXTpUi1YsEBffPGFBg0aZI17vV51795djRo1UlZWll5++WWNGzdO77zzjlWzatUqPfjggxowYIC+/fZb9ejRQz169NCWLVvOqxcAAHCFMn40ZswYc8MNN5x1vKSkxERHR5uXX37ZWpeXl2dcLpf5f//v/xljjNm2bZuRZNauXWvVLF682DgcDvPTTz8ZY4x56623TM2aNU1BQYHPtlu0aGE9fuCBB0xSUpLP9uPj480TTzxR4V7OJT8/30gy+fn5Far3G4nFrgUAUOVV9P3br0eqPv30U3Xq1En333+/6tatq2uvvVb//Oc/rfHdu3crOztbiYmJ1rrw8HDFx8crMzNTkpSZmamIiAh16tTJqklMTFRAQIBWr15t1dx0001yOp1Wjcfj0c6dO3XkyBGr5vTtlNaUbqcivZypoKBAXq/XZwEAAJcnv4aq//znP5o2bZqaNWumJUuWaMiQIXryySc1c+ZMSVJ2drYkKSoqyud5UVFR1lh2drbq1q3rM16tWjXVqlXLp6a8OU7fxtlqTh8/Vy9nmjBhgsLDw60lJibmXC8JAACoovwaqkpKStShQwf9/e9/17XXXqtBgwbp8ccf1/Tp0/3Zlm1SUlKUn59vLfv27fN3SwAA4CLxa6iqV6+e4uLifNa1atVKe/fulSRFR0dLknJycnxqcnJyrLHo6Gjl5ub6jJ86dUqHDx/2qSlvjtO3cbaa08fP1cuZXC6X3G63zwIAAC5Pfg1Vf/jDH7Rz506fdd99950aNWokSWrcuLGio6OVkZFhjXu9Xq1evVoJCQmSpISEBOXl5SkrK8uqWbZsmUpKShQfH2/VfPHFFyoqKrJqli5dqhYtWlhXGiYkJPhsp7SmdDsV6QUAAFzBLtGJ8+Vas2aNqVatmnnxxRfNrl27zAcffGBCQkLM+++/b9W89NJLJiIiwvz73/82mzZtMnfffbdp3LixOXHihFVz++23m2uvvdasXr3afPXVV6ZZs2bmwQcftMbz8vJMVFSUeeSRR8yWLVvM7NmzTUhIiHn77betmq+//tpUq1bNvPLKK2b79u0mNTXVVK9e3WzevPm8evktXP13BS4AgCqvou/ffv+tP3/+fNOmTRvjcrlMy5YtzTvvvOMzXlJSYp5//nkTFRVlXC6XufXWW83OnTt9an7++Wfz4IMPmrCwMON2u03//v3N0aNHfWo2btxobrjhBuNyucxVV11lXnrppTK9fPjhh6Z58+bG6XSa1q1bm4ULF553L7+FUHUFLgCAKq+i798OY4zx77GyK4fX61V4eLjy8/Mr9/lVDoe/O7h88M8LAKq8ir5/+/1ragAAAC4HhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqAIAALCBX0PVuHHj5HA4fJaWLVta4ydPnlRycrJq166tsLAw9ezZUzk5OT5z7N27V0lJSQoJCVHdunX1zDPP6NSpUz41K1asUIcOHeRyudS0aVOlpaWV6WXq1KmKjY1VUFCQ4uPjtWbNGp/xivQCAACuXH4/UtW6dWsdOHDAWr766itrbMSIEZo/f77mzp2rlStXav/+/br33nut8eLiYiUlJamwsFCrVq3SzJkzlZaWprFjx1o1u3fvVlJSkrp166YNGzZo+PDhGjhwoJYsWWLVzJkzRyNHjlRqaqrWr1+vdu3ayePxKDc3t8K9AACAK5zxo9TUVNOuXbtyx/Ly8kz16tXN3LlzrXXbt283kkxmZqYxxphFixaZgIAAk52dbdVMmzbNuN1uU1BQYIwxZvTo0aZ169Y+c/fq1ct4PB7rcZcuXUxycrL1uLi42NSvX99MmDChwr1URH5+vpFk8vPzK/wcv5BY7FoAAFVeRd+//X6kateuXapfv76uvvpq9enTR3v37pUkZWVlqaioSImJiVZty5Yt1bBhQ2VmZkqSMjMz1bZtW0VFRVk1Ho9HXq9XW7dutWpOn6O0pnSOwsJCZWVl+dQEBAQoMTHRqqlIL+UpKCiQ1+v1WQAAwOXJr6EqPj5eaWlpSk9P17Rp07R7927deOONOnr0qLKzs+V0OhUREeHznKioKGVnZ0uSsrOzfQJV6Xjp2G/VeL1enThxQocOHVJxcXG5NafPca5eyjNhwgSFh4dbS0xMTMVeGAAAUOVU8+fG77jjDuvP11xzjeLj49WoUSN9+OGHCg4O9mNn9khJSdHIkSOtx16vl2AFAMBlyu8f/50uIiJCzZs31/fff6/o6GgVFhYqLy/PpyYnJ0fR0dGSpOjo6DJX4JU+PleN2+1WcHCw6tSpo8DAwHJrTp/jXL2Ux+Vyye12+ywAAODyVKlC1bFjx/TDDz+oXr166tixo6pXr66MjAxrfOfOndq7d68SEhIkSQkJCdq8ebPPVXpLly6V2+1WXFycVXP6HKU1pXM4nU517NjRp6akpEQZGRlWTUV6AQAAV7hLdOJ8uUaNGmVWrFhhdu/ebb7++muTmJho6tSpY3Jzc40xxgwePNg0bNjQLFu2zKxbt84kJCSYhIQE6/mnTp0ybdq0Md27dzcbNmww6enpJjIy0qSkpFg1//nPf0xISIh55plnzPbt283UqVNNYGCgSU9Pt2pmz55tXC6XSUtLM9u2bTODBg0yERERPlcVnquXiuDqvytwAQBUeRV9//brb/1evXqZevXqGafTaa666irTq1cv8/3331vjJ06cMH/6059MzZo1TUhIiLnnnnvMgQMHfObYs2ePueOOO0xwcLCpU6eOGTVqlCkqKvKpWb58uWnfvr1xOp3m6quvNjNmzCjTy5tvvmkaNmxonE6n6dKli/nmm298xivSy7kQqq7ABQBQ5VX0/dthjDH+PVZ25fB6vQoPD1d+fn7lPr/K4fB3B5cP/nkBQJVX0ffvSnVOFQAAQFVFqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAG1TzdwMAUBGO8Q5/t3BZMKnG3y0Aly2OVAEAANiAUAUAAGADQhUAAIANCFUAAAA2IFQBAADYgFAFAABgA0IVAACADS4oVF199dX6+eefy6zPy8vT1Vdf/bubAgAAqGouKFTt2bNHxcXFZdYXFBTop59++t1NAQAAVDXndUf1Tz/91PrzkiVLFB4ebj0uLi5WRkaGYmNjbWsOAACgqjivUNWjRw9JksPhUN++fX3GqlevrtjYWE2aNMm25gAAAKqK8wpVJSUlkqTGjRtr7dq1qlOnzkVpCgAAoKq5oC9U3r17t919AAAAVGkXFKokKSMjQxkZGcrNzbWOYJX6n//5n9/dGAAAldn48eP93cJlIzU11d8t2OKCQtX48eP1wgsvqFOnTqpXr54cDofdfQEAAFQpFxSqpk+frrS0ND3yyCN29wMAAFAlXdB9qgoLC3X99dfb2shLL70kh8Oh4cOHW+tOnjyp5ORk1a5dW2FhYerZs6dycnJ8nrd3714lJSUpJCREdevW1TPPPKNTp0751KxYsUIdOnSQy+VS06ZNlZaWVmb7U6dOVWxsrIKCghQfH681a9b4jFekFwAAcOW6oFA1cOBAzZo1y7Ym1q5dq7ffflvXXHONz/oRI0Zo/vz5mjt3rlauXKn9+/fr3nvvtcaLi4uVlJSkwsJCrVq1SjNnzlRaWprGjh1r1ezevVtJSUnq1q2bNmzYoOHDh2vgwIFasmSJVTNnzhyNHDlSqampWr9+vdq1ayePx6Pc3NwK9wIAAK5sDmOMOd8nPfXUU3r33Xd1zTXX6JprrlH16tV9xl999dUKz3Xs2DF16NBBb731lv72t7+pffv2mjx5svLz8xUZGalZs2bpvvvukyTt2LFDrVq1UmZmpq677jotXrxYd911l/bv36+oqChJv340OWbMGB08eFBOp1NjxozRwoULtWXLFmubvXv3Vl5entLT0yVJ8fHx6ty5s6ZMmSLp11tHxMTEaNiwYXr22Wcr1EtFeL1ehYeHKz8/X263u8Kv0SXHOXL2Of9/XjgLx3j2SzuYVPZJu3Ciun0q+4nqFX3/vqAjVZs2bVL79u0VEBCgLVu26Ntvv7WWDRs2nNdcycnJSkpKUmJios/6rKwsFRUV+axv2bKlGjZsqMzMTElSZmam2rZtawUqSfJ4PPJ6vdq6datVc+bcHo/HmqOwsFBZWVk+NQEBAUpMTLRqKtJLeQoKCuT1en0WAABwebqgE9WXL19uy8Znz56t9evXa+3atWXGsrOz5XQ6FRER4bM+KipK2dnZVs3pgap0vHTst2q8Xq9OnDihI0eOqLi4uNyaHTt2VLiX8kyYMIH/yQAAcIW4oCNVdti3b5+eeuopffDBBwoKCvJXGxdVSkqK8vPzrWXfvn3+bgkAAFwkF3Skqlu3br95b6ply5adc46srCzl5uaqQ4cO1rri4mJ98cUXmjJlipYsWaLCwkLl5eX5HCHKyclRdHS0JCk6OrrMVXqlV+SdXnPmVXo5OTlyu90KDg5WYGCgAgMDy605fY5z9VIel8sll8t1ztcCAABUfRd0pKp9+/Zq166dtcTFxamwsFDr169X27ZtKzTHrbfeqs2bN2vDhg3W0qlTJ/Xp08f6c/Xq1ZWRkWE9Z+fOndq7d68SEhIkSQkJCdq8ebPPVXpLly6V2+1WXFycVXP6HKU1pXM4nU517NjRp6akpEQZGRlWTceOHc/ZCwAAuLJd0JGq1157rdz148aN07Fjxyo0R40aNdSmTRufdaGhoapdu7a1fsCAARo5cqRq1aolt9utYcOGKSEhwbrarnv37oqLi9MjjzyiiRMnKjs7W88995ySk5OtI0SDBw/WlClTNHr0aD322GNatmyZPvzwQy1cuNDa7siRI9W3b1916tRJXbp00eTJk3X8+HH1799fkhQeHn7OXgAAwJXtgr/7rzwPP/ywunTpoldeecWW+V577TUFBASoZ8+eKigokMfj0VtvvWWNBwYGasGCBRoyZIgSEhIUGhqqvn376oUXXrBqGjdurIULF2rEiBF6/fXX1aBBA/3rX/+Sx+Oxanr16qWDBw9q7Nixys7OVvv27ZWenu5z8vq5egEAAFe2C7pP1dm89957GjNmjPbv32/XlJcV7lN1BeI+VbbhPlX24D5V9uHqbvtcLvepuqAjVWfeSdwYowMHDmjdunV6/vnnL2RKAACAKu2CQlV4eLjP44CAALVo0UIvvPCCunfvbktjAAAAVckFhaoZM2bY3QcAAECV9rtOVM/KytL27dslSa1bt9a1115rS1MAAABVzQWFqtzcXPXu3VsrVqywboaZl5enbt26afbs2YqMjLSzRwAAgErvgm7+OWzYMB09elRbt27V4cOHdfjwYW3ZskVer1dPPvmk3T0CAABUehd0pCo9PV2ff/65WrVqZa2Li4vT1KlTOVEdAABckS7oSFVJSYmqV69eZn316tVVUlLyu5sCAACoai4oVN1yyy166qmnfG7y+dNPP2nEiBG69dZbbWsOAACgqrigUDVlyhR5vV7FxsaqSZMmatKkiRo3biyv16s333zT7h4BAAAqvQs6pyomJkbr16/X559/rh07dkiSWrVqpcTERFubAwAAqCrO60jVsmXLFBcXJ6/XK4fDodtuu03Dhg3TsGHD1LlzZ7Vu3VpffvnlxeoVAACg0jqvUDV58mQ9/vjj5X6ZYHh4uJ544gm9+uqrtjUHAABQVZxXqNq4caNuv/32s453795dWVlZv7spAACAqua8QlVOTk65t1IoVa1aNR08ePB3NwUAAFDVnFeouuqqq7Rly5azjm/atEn16tX73U0BAABUNecVqu688049//zzOnnyZJmxEydOKDU1VXfddZdtzQEAAFQV53VLheeee04ff/yxmjdvrqFDh6pFixaSpB07dmjq1KkqLi7WX/7yl4vSKAAAQGV2XqEqKipKq1at0pAhQ5SSkiJjjCTJ4XDI4/Fo6tSpioqKuiiNAgAAVGbnffPPRo0aadGiRTpy5Ii+//57GWPUrFkz1axZ82L0BwAAUCVc0B3VJalmzZrq3Lmznb0AAABUWRf03X8AAADwRagCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABn4NVdOmTdM111wjt9stt9uthIQELV682Bo/efKkkpOTVbt2bYWFhalnz57KycnxmWPv3r1KSkpSSEiI6tatq2eeeUanTp3yqVmxYoU6dOggl8ulpk2bKi0trUwvU6dOVWxsrIKCghQfH681a9b4jFekFwAAcOXya6hq0KCBXnrpJWVlZWndunW65ZZbdPfdd2vr1q2SpBEjRmj+/PmaO3euVq5cqf379+vee++1nl9cXKykpCQVFhZq1apVmjlzptLS0jR27FirZvfu3UpKSlK3bt20YcMGDR8+XAMHDtSSJUusmjlz5mjkyJFKTU3V+vXr1a5dO3k8HuXm5lo15+oFAABc2RzGGOPvJk5Xq1Ytvfzyy7rvvvsUGRmpWbNm6b777pMk7dixQ61atVJmZqauu+46LV68WHfddZf279+vqKgoSdL06dM1ZswYHTx4UE6nU2PGjNHChQu1ZcsWaxu9e/dWXl6e0tPTJUnx8fHq3LmzpkyZIkkqKSlRTEyMhg0bpmeffVb5+fnn7KUivF6vwsPDlZ+fL7fbbdtrZjuHw98dXD4q1z+vKs0xnv3SDiaVfdIu48eP93cLl43U1FR/t/CbKvr+XWnOqSouLtbs2bN1/PhxJSQkKCsrS0VFRUpMTLRqWrZsqYYNGyozM1OSlJmZqbZt21qBSpI8Ho+8Xq91tCszM9NnjtKa0jkKCwuVlZXlUxMQEKDExESrpiK9lKegoEBer9dnAQAAlye/h6rNmzcrLCxMLpdLgwcP1ieffKK4uDhlZ2fL6XQqIiLCpz4qKkrZ2dmSpOzsbJ9AVTpeOvZbNV6vVydOnNChQ4dUXFxcbs3pc5yrl/JMmDBB4eHh1hITE1OxFwUAAFQ5fg9VLVq00IYNG7R69WoNGTJEffv21bZt2/zdli1SUlKUn59vLfv27fN3SwAA4CKp5u8GnE6nmjZtKknq2LGj1q5dq9dff129evVSYWGh8vLyfI4Q5eTkKDo6WpIUHR1d5iq90ivyTq858yq9nJwcud1uBQcHKzAwUIGBgeXWnD7HuXopj8vlksvlOo9XAwAAVFV+P1J1ppKSEhUUFKhjx46qXr26MjIyrLGdO3dq7969SkhIkCQlJCRo8+bNPlfpLV26VG63W3FxcVbN6XOU1pTO4XQ61bFjR5+akpISZWRkWDUV6QUAAFzZ/HqkKiUlRXfccYcaNmyoo0ePatasWVqxYoWWLFmi8PBwDRgwQCNHjlStWrXkdrs1bNgwJSQkWFfbde/eXXFxcXrkkUc0ceJEZWdn67nnnlNycrJ1hGjw4MGaMmWKRo8erccee0zLli3Thx9+qIULF1p9jBw5Un379lWnTp3UpUsXTZ48WcePH1f//v0lqUK9AACAK5tfQ1Vubq4effRRHThwQOHh4brmmmu0ZMkS3XbbbZKk1157TQEBAerZs6cKCgrk8Xj01ltvWc8PDAzUggULNGTIECUkJCg0NFR9+/bVCy+8YNU0btxYCxcu1IgRI/T666+rQYMG+te//iWPx2PV9OrVSwcPHtTYsWOVnZ2t9u3bKz093efk9XP1AgAArmyV7j5VlzPuU3UF4p+XbbhPlT24T5V9uE+VfbhPFQAAACyEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsIFfQ9WECRPUuXNn1ahRQ3Xr1lWPHj20c+dOn5qTJ08qOTlZtWvXVlhYmHr27KmcnByfmr179yopKUkhISGqW7eunnnmGZ06dcqnZsWKFerQoYNcLpeaNm2qtLS0Mv1MnTpVsbGxCgoKUnx8vNasWXPevQAAgCuTX0PVypUrlZycrG+++UZLly5VUVGRunfvruPHj1s1I0aM0Pz58zV37lytXLlS+/fv17333muNFxcXKykpSYWFhVq1apVmzpyptLQ0jR071qrZvXu3kpKS1K1bN23YsEHDhw/XwIEDtWTJEqtmzpw5GjlypFJTU7V+/Xq1a9dOHo9Hubm5Fe4FAABcuRzGGOPvJkodPHhQdevW1cqVK3XTTTcpPz9fkZGRmjVrlu677z5J0o4dO9SqVStlZmbquuuu0+LFi3XXXXdp//79ioqKkiRNnz5dY8aM0cGDB+V0OjVmzBgtXLhQW7ZssbbVu3dv5eXlKT09XZIUHx+vzp07a8qUKZKkkpISxcTEaNiwYXr22Wcr1Mu5eL1ehYeHKz8/X26329bXzlYOh787uHxUnn9eVZ5jPPulHUwq+6Rdxo8f7+8WLhupqan+buE3VfT9u1KdU5Wfny9JqlWrliQpKytLRUVFSkxMtGpatmyphg0bKjMzU5KUmZmptm3bWoFKkjwej7xer7Zu3WrVnD5HaU3pHIWFhcrKyvKpCQgIUGJiolVTkV4AAMCVq5q/GyhVUlKi4cOH6w9/+IPatGkjScrOzpbT6VRERIRPbVRUlLKzs62a0wNV6Xjp2G/VeL1enThxQkeOHFFxcXG5NTt27KhwL2cqKChQQUGB9djr9Z7rZQAAAFVUpTlSlZycrC1btmj27Nn+bsU2EyZMUHh4uLXExMT4uyUAAHCRVIpQNXToUC1YsEDLly9XgwYNrPXR0dEqLCxUXl6eT31OTo6io6OtmjOvwCt9fK4at9ut4OBg1alTR4GBgeXWnD7HuXo5U0pKivLz861l3759FXg1AABAVeTXUGWM0dChQ/XJJ59o2bJlaty4sc94x44dVb16dWVkZFjrdu7cqb179yohIUGSlJCQoM2bN/tcpbd06VK53W7FxcVZNafPUVpTOofT6VTHjh19akpKSpSRkWHVVKSXM7lcLrndbp8FAABcnvx6TlVycrJmzZqlf//736pRo4Z1blJ4eLiCg4MVHh6uAQMGaOTIkapVq5bcbreGDRumhIQE62q77t27Ky4uTo888ogmTpyo7OxsPffcc0pOTpbL5ZIkDR48WFOmTNHo0aP12GOPadmyZfrwww+1cOFCq5eRI0eqb9++6tSpk7p06aLJkyfr+PHj6t+/v9XTuXoBAABXLr+GqmnTpkmSbr75Zp/1M2bMUL9+/SRJr732mgICAtSzZ08VFBTI4/HorbfesmoDAwO1YMECDRkyRAkJCQoNDVXfvn31wgsvWDWNGzfWwoULNWLECL3++utq0KCB/vWvf8nj8Vg1vXr10sGDBzV27FhlZ2erffv2Sk9P9zl5/Vy9AACAK1eluk/V5Y77VF2B+OdlG+5TZQ/uU2Uf7lNlH+5TBQAAAAuhCgAAwAaEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsIFfQ9UXX3yhP/7xj6pfv74cDofmzZvnM26M0dixY1WvXj0FBwcrMTFRu3bt8qk5fPiw+vTpI7fbrYiICA0YMEDHjh3zqdm0aZNuvPFGBQUFKSYmRhMnTizTy9y5c9WyZUsFBQWpbdu2WrRo0Xn3AgAArlx+DVXHjx9Xu3btNHXq1HLHJ06cqDfeeEPTp0/X6tWrFRoaKo/Ho5MnT1o1ffr00datW7V06VItWLBAX3zxhQYNGmSNe71ede/eXY0aNVJWVpZefvlljRs3Tu+8845Vs2rVKj344IMaMGCAvv32W/Xo0UM9evTQli1bzqsXAABw5XIYY4y/m5Akh8OhTz75RD169JD065Gh+vXra9SoUXr66aclSfn5+YqKilJaWpp69+6t7du3Ky4uTmvXrlWnTp0kSenp6brzzjv13//+V/Xr19e0adP0l7/8RdnZ2XI6nZKkZ599VvPmzdOOHTskSb169dLx48e1YMECq5/rrrtO7du31/Tp0yvUS0V4vV6Fh4crPz9fbrfbltftonA4/N3B5aNy/PO6LDjGs1/awaSyT9pl/Pjx/m7hspGamurvFn5TRd+/K+05Vbt371Z2drYSExOtdeHh4YqPj1dmZqYkKTMzUxEREVagkqTExEQFBARo9erVVs1NN91kBSpJ8ng82rlzp44cOWLVnL6d0prS7VSkl/IUFBTI6/X6LAAA4PJUaUNVdna2JCkqKspnfVRUlDWWnZ2tunXr+oxXq1ZNtWrV8qkpb47Tt3G2mtPHz9VLeSZMmKDw8HBriYmJOcdPDQAAqqpKG6ouBykpKcrPz7eWffv2+bslAABwkVTaUBUdHS1JysnJ8Vmfk5NjjUVHRys3N9dn/NSpUzp8+LBPTXlznL6Ns9WcPn6uXsrjcrnkdrt9FgAAcHmqtKGqcePGio6OVkZGhrXO6/Vq9erVSkhIkCQlJCQoLy9PWVlZVs2yZctUUlKi+Ph4q+aLL75QUVGRVbN06VK1aNFCNWvWtGpO305pTel2KtILAAC4svk1VB07dkwbNmzQhg0bJP16QviGDRu0d+9eORwODR8+XH/729/06aefavPmzXr00UdVv3596wrBVq1a6fbbb9fjjz+uNWvW6Ouvv9bQoUPVu3dv1a9fX5L00EMPyel0asCAAdq6davmzJmj119/XSNHjrT6eOqpp5Senq5JkyZpx44dGjdunNatW6ehQ4dKUoV6AQAAV7Zq/tz4unXr1K1bN+txadDp27ev0tLSNHr0aB0/flyDBg1SXl6ebrjhBqWnpysoKMh6zgcffKChQ4fq1ltvVUBAgHr27Kk33njDGg8PD9dnn32m5ORkdezYUXXq1NHYsWN97mV1/fXXa9asWXruuef05z//Wc2aNdO8efPUpk0bq6YivQAAgCtXpblP1ZWA+1RdgfjnZRvuU2UP7lNlH+5TZR/uUwUAAAALoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbECoAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqDpPU6dOVWxsrIKCghQfH681a9b4uyUAAFAJEKrOw5w5czRy5EilpqZq/fr1ateunTwej3Jzc/3dGgAA8DNC1Xl49dVX9fjjj6t///6Ki4vT9OnTFRISov/5n//xd2sAAMDPCFUVVFhYqKysLCUmJlrrAgIClJiYqMzMTD92BgAAKoNq/m6gqjh06JCKi4sVFRXlsz4qKko7duwo9zkFBQUqKCiwHufn50uSvF7vxWsUlQt/1/Y56e8GLg/8/rHPyZPslHap7PtlaX/GmN+sI1RdRBMmTND48ePLrI+JifFDN/CL8HB/dwD4CH+JfRKVz0svveTvFirk6NGjCv+N3+uEqgqqU6eOAgMDlZOT47M+JydH0dHR5T4nJSVFI0eOtB6XlJTo8OHDql27thwOx0Xt93Ln9XoVExOjffv2ye12+7sdgH0SlQ77pH2MMTp69Kjq16//m3WEqgpyOp3q2LGjMjIy1KNHD0m/hqSMjAwNHTq03Oe4XC65XC6fdRERERe50yuL2+3mlwUqFfZJVDbsk/b4rSNUpQhV52HkyJHq27evOnXqpC5dumjy5Mk6fvy4+vfv7+/WAACAnxGqzkOvXr108OBBjR07VtnZ2Wrfvr3S09PLnLwOAACuPISq8zR06NCzftyHS8flcik1NbXMx6uAv7BPorJhn7z0HOZc1wcCAADgnLj5JwAAgA0IVQAAADYgVAEAANiAUIUrQmxsrCZPnuzvNoALsmLFCjkcDuXl5fm7FVQBFd1f+L1oP0IVfrd+/frJ4XCU+ZqBefPmXfI7x6elpZV7g9W1a9dq0KBBl7QXVD6Xal/ds2ePHA6HNmzYYNucuPyU7o8Oh0NOp1NNmzbVCy+8oFOnTv2uea+//nodOHDAulklvxcvHUIVbBEUFKR//OMfOnLkiL9bKVdkZKRCQkL83QYqgcq0rxYWFvq7BfjZ7bffrgMHDmjXrl0aNWqUxo0bp5dffvl3zel0OhUdHX3O/yjwe9F+hCrYIjExUdHR0ZowYcJZa7766ivdeOONCg4OVkxMjJ588kkdP37cGj9w4ICSkpIUHBysxo0ba9asWWUOT7/66qtq27atQkNDFRMToz/96U86duyYpF8Peffv31/5+fnW//7GjRsnyfcw90MPPaRevXr59FZUVKQ6dero3XfflfTrVxBNmDBBjRs3VnBwsNq1a6ePPvrIhlcK/mbHvupwODRv3jyf50RERCgtLU2S1LhxY0nStddeK4fDoZtvvlnSr0cmevTooRdffFH169dXixYtJEnvvfeeOnXqpBo1aig6OloPPfSQcnNz7fuhUWm5XC5FR0erUaNGGjJkiBITE/Xpp5/qyJEjevTRR1WzZk2FhITojjvu0K5du6zn/fjjj/rjH/+omjVrKjQ0VK1bt9aiRYsk+X78x+/FS4tQBVsEBgbq73//u958803997//LTP+ww8/6Pbbb1fPnj21adMmzZkzR1999ZXPjVQfffRR7d+/XytWrND//u//6p133inzxhIQEKA33nhDW7du1cyZM7Vs2TKNHj1a0q+HvCdPniy3260DBw7owIEDevrpp8v00qdPH82fP98KY5K0ZMkS/fLLL7rnnnskSRMmTNC7776r6dOna+vWrRoxYoQefvhhrVy50pbXC/5jx756LmvWrJEkff755zpw4IA+/vhjaywjI0M7d+7U0qVLtWDBAkm/vnn99a9/1caNGzVv3jzt2bNH/fr1+30/KKqk4OBgFRYWql+/flq3bp0+/fRTZWZmyhijO++8U0VFRZKk5ORkFRQU6IsvvtDmzZv1j3/8Q2FhYWXm4/fiJWaA36lv377m7rvvNsYYc91115nHHnvMGGPMJ598Ykp3sQEDBphBgwb5PO/LL780AQEB5sSJE2b79u1Gklm7dq01vmvXLiPJvPbaa2fd9ty5c03t2rWtxzNmzDDh4eFl6ho1amTNU1RUZOrUqWPeffdda/zBBx80vXr1MsYYc/LkSRMSEmJWrVrlM8eAAQPMgw8++NsvBio1O/ZVY4yRZD755BOfmvDwcDNjxgxjjDG7d+82ksy3335bZvtRUVGmoKDgN/tcu3atkWSOHj1qjDFm+fLlRpI5cuTIef7EqMxO3x9LSkrM0qVLjcvlMj169DCSzNdff23VHjp0yAQHB5sPP/zQGGNM27Ztzbhx48qd98z9hd+Llw5fUwNb/eMf/9Att9xS5n9CGzdu1KZNm/TBBx9Y64wxKikp0e7du/Xdd9+pWrVq6tChgzXetGlT1axZ02eezz//XBMmTNCOHTvk9Xp16tQpnTx5Ur/88kuFzw2oVq2aHnjgAX3wwQd65JFHdPz4cf373//W7NmzJUnff/+9fvnlF912220+zyssLNS11157Xq8HKq8L3VdbtWr1u7bbtm1bOZ1On3VZWVkaN26cNm7cqCNHjqikpESStHfvXsXFxf2u7aFyW7BggcLCwlRUVKSSkhI99NBDuvfee7VgwQLFx8dbdbVr11aLFi20fft2SdKTTz6pIUOG6LPPPlNiYqJ69uypa6655oL74PeiPQhVsNVNN90kj8ejlJQUn48vjh07pieeeEJPPvlkmec0bNhQ33333Tnn3rNnj+666y4NGTJEL774omrVqqWvvvpKAwYMUGFh4XmdcNmnTx917dpVubm5Wrp0qYKDg3X77bdbvUrSwoULddVVV/k8j+/Qunxc6L4q/XpOlTnjG75KP5Y5l9DQUJ/Hx48fl8fjkcfj0QcffKDIyEjt3btXHo+HE9mvAN26ddO0adPkdDpVv359VatWTZ9++uk5nzdw4EB5PB4tXLhQn332mSZMmKBJkyZp2LBhF9wLvxd/P0IVbPfSSy+pffv21km4ktShQwdt27ZNTZs2Lfc5LVq00KlTp/Ttt9+qY8eOkn79n9HpV2hlZWWppKREkyZNUkDAr6cDfvjhhz7zOJ1OFRcXn7PH66+/XjExMZozZ44WL16s+++/X9WrV5ckxcXFyeVyae/everatev5/fCoUi5kX5V+vWrqwIED1uNdu3bpl19+sR6XHomqyL64Y8cO/fzzz3rppZcUExMjSVq3bt15/yyomkJDQ8vsa61atdKpU6e0evVqXX/99ZKkn3/+WTt37vQ5chkTE6PBgwdr8ODBSklJ0T//+c9yQxW/Fy8dQhVs17ZtW/Xp00dvvPGGtW7MmDG67rrrNHToUA0cOFChoaHatm2bli5dqilTpqhly5ZKTEzUoEGDNG3aNFWvXl2jRo1ScHCwdVlw06ZNVVRUpDfffFN//OMf9fXXX2v69Ok+246NjdWxY8eUkZGhdu3aKSQk5KxHsB566CFNnz5d3333nZYvX26tr1Gjhp5++mmNGDFCJSUluuGGG5Sfn6+vv/5abrdbffv2vQivGvzhQvZVSbrllls0ZcoUJSQkqLi4WGPGjLHefCSpbt26Cg4OVnp6uho0aKCgoCDrnkFnatiwoZxOp958800NHjxYW7Zs0V//+teL+4OjUmvWrJnuvvtuPf7443r77bdVo0YNPfvss7rqqqt09913S5KGDx+uO+64Q82bN9eRI0e0fPnys340ze/FS8jP53ThMnD6yZaldu/ebZxOpzl9F1uzZo257bbbTFhYmAkNDTXXXHONefHFF63x/fv3mzvuuMO4XC7TqFEjM2vWLFO3bl0zffp0q+bVV1819erVM8HBwcbj8Zh33323zAm8gwcPNrVr1zaSTGpqqjHG94TMUtu2bTOSTKNGjUxJSYnPWElJiZk8ebJp0aKFqV69uomMjDQej8esXLny971Y8Cu79tWffvrJdO/e3YSGhppmzZqZRYsW+Zyobowx//znP01MTIwJCAgwXbt2Pev2jTFm1qxZJjY21rhcLpOQkGA+/fRTnxPdOVH98nS2/cEYYw4fPmweeeQREx4ebv2+++6776zxoUOHmiZNmhiXy2UiIyPNI488Yg4dOmSMKX9/4ffipeEw5owTA4BK4r///a9iYmL0+eef69Zbb/V3OwAA/CZCFSqNZcuW6dixY2rbtq0OHDig0aNH66efftJ3333n89EKAACVEedUodIoKirSn//8Z/3nP/9RjRo1dP311+uDDz4gUAEAqgSOVAEAANiAr6kBAACwAaEKAADABoQqAAAAGxCqAAAAbECoAoALtGLFCjkcDuXl5fm7FQCVAKEKQJV38OBBDRkyRA0bNpTL5VJ0dLQ8Ho++/vpr27Zx8803a/jw4T7rrr/+eh04cOCsX0FzKfXr1089evTwdxvAFY37VAGo8nr27KnCwkLNnDlTV199tXJycpSRkaGff/75om7X6XQqOjr6om4DQBXiz+/IAYDf68iRI0aSWbFixW/WDBgwwNSpU8fUqFHDdOvWzWzYsMEaT01NNe3atTPvvvuuadSokXG73aZXr17G6/UaY379jjZJPsvu3bvLfMfajBkzTHh4uJk/f75p3ry5CQ4ONj179jTHjx83aWlpplGjRiYiIsIMGzbMnDp1ytr+yZMnzahRo0z9+vVNSEiI6dKli1m+fLk1Xjpvenq6admypQkNDTUej8fs37/f6v/M/k5/PoBLg4//AFRpYWFhCgsL07x581RQUFBuzf3336/c3FwtXrxYWVlZ6tChg2699VYdPnzYqvnhhx80b948LViwQAsWLNDKlSv10ksvSZJef/11JSQk6PHHH9eBAwd04MABxcTElLutX375RW+88YZmz56t9PR0rVixQvfcc48WLVqkRYsW6b333tPbb7+tjz76yHrO0KFDlZmZqdmzZ2vTpk26//77dfvtt2vXrl0+877yyit677339MUXX2jv3r16+umnJUlPP/20HnjgAd1+++1Wf9dff/3vfm0BnCd/pzoA+L0++ugjU7NmTRMUFGSuv/56k5KSYjZu3GiMMebLL780brfbnDx50uc5TZo0MW+//bYx5tcjPSEhIdaRKWOMeeaZZ0x8fLz1uGvXruapp57ymaO8I1WSzPfff2/VPPHEEyYkJMQcPXrUWufxeMwTTzxhjDHmxx9/NIGBgeann37ymfvWW281KSkpZ5136tSpJioqynrct29fc/fdd1fo9QJwcXBOFYAqr2fPnkpKStKXX36pb775RosXL9bEiRP1r3/9S8ePH9exY8dUu3Ztn+ecOHFCP/zwg/U4NjZWNWrUsB7Xq1dPubm5591LSEiImjRpYj2OiopSbGyswsLCfNaVzr1582YVFxerefPmPvMUFBT49HzmvBfaH4CLh1AF4LIQFBSk2267Tbfddpuef/55DRw4UKmpqfrTn/6kevXqacWKFWWeExERYf35zC/udjgcKikpOe8+ypvnt+Y+duyYAgMDlZWVpcDAQJ+604NYeXMYvroVqFQIVQAuS3FxcZo3b546dOig7OxsVatWTbGxsRc8n9PpVHFxsX0N/v+uvfZaFRcXKzc3VzfeeOMFz3Ox+gNQcZyoDqBK+/nnn3XLLbfo/fff16ZNm7R7927NnTtXEydO1N13363ExEQlJCSoR48e+uyzz7Rnzx6tWrVKf/nLX7Ru3boKbyc2NlarV6/Wnj17dOjQoQs6ilWe5s2bq0+fPnr00Uf18ccfa/fu3VqzZo0mTJighQsXnld/mzZt0s6dO3Xo0CEVFRXZ0h+AiiNUAajSwsLCFB8fr9dee0033XST2rRpo+eff16PP/64pkyZIofDoUWLFummm25S//791bx5c/Xu3Vs//vijoqKiKrydp59+WoGBgYqLi1NkZKT27t1r288wY8YMPfrooxo1apRatGihHj16aO3atWrYsGGF53j88cfVokULderUSZGRkbbe+BRAxTgMH8oDAAD8bhypAgAAsAGhCgAAwAaEKgAAABsQqgAAAGxAqAIAALABoQoAAMAGhCoAAAAbEKoAAABsQKgCAACwAaEKAADABoQqAAAAGxCqAAAAbPD/AUA/ZGeZMZqnAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Download necessary NLTK datasets\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/tw/training.1600000.processed.noemoticon.csv'  # Adjust path\n",
        "df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
        "\n",
        "# Rename columns\n",
        "df.columns = ['tweet_id', 'user_id', 'timestamp', 'query', 'user_handle', 'tweet_text']\n",
        "\n",
        "# Initialize VADER Sentiment Analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to classify sentiment using VADER\n",
        "def get_sentiment(text):\n",
        "    score = sia.polarity_scores(text)['compound']\n",
        "    if score > 0.05:\n",
        "        return 'positive'\n",
        "    elif score < -0.05:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# Apply sentiment labeling\n",
        "df['sentiment'] = df['tweet_text'].apply(get_sentiment)\n",
        "\n",
        "# Function for text preprocessing\n",
        "def clean_text(text):\n",
        "    # Remove non-alphabetic characters and lowercase\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text.lower())\n",
        "    # Tokenize\n",
        "    words = text.split()\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    # Lemmatize words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply text cleaning\n",
        "df['cleaned_text'] = df['tweet_text'].apply(clean_text)\n",
        "\n",
        "# Convert categorical labels to numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['sentiment_label'] = label_encoder.fit_transform(df['sentiment'])  # (negative=0, neutral=1, positive=2)\n",
        "\n",
        "# Splitting data\n",
        "X = df['cleaned_text']\n",
        "y = df['sentiment_label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Tokenization\n",
        "max_words = 5000  # Vocabulary size\n",
        "max_len = 100  # Sequence length\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Padding sequences\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "# Build LSTM Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=64, input_length=max_len),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32),\n",
        "    Dropout(0.2),\n",
        "    Dense(3, activation='softmax')  # Output layer for 3 classes\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "history = model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test))\n",
        "\n",
        "# Evaluate Model\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
        "print(f\"\\nDeep Learning Model - LSTM Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Plot Training Loss & Accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training vs. Validation Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training vs. Validation Accuracy')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "G1TlFV8dtMCC",
        "outputId": "f678a269-9780-4801-8a9c-d2a1354f9a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/tw/training.1600000.processed.noemoticon.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9003d5ca0b62>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/tw/training.1600000.processed.noemoticon.csv'\u001b[0m  \u001b[0;31m# Adjust path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ISO-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Rename columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/tw/training.1600000.processed.noemoticon.csv'"
          ]
        }
      ]
    }
  ]
}